import streamlit as st
import pandas as pd
import requests
import urllib.parse
import time
import math
import xml.etree.ElementTree as ET
import urllib3

# SSL ê²½ê³  ë¬´ì‹œ
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

st.set_page_config(page_title="2026 ì‹¤ì‹œê°„ ìˆ˜ì§ˆ(í™•ì •)", layout="wide")
st.title("ğŸ§ª ê¸ˆê°• ìˆ˜ê³„ ì‹¤ì‹œê°„ ìˆ˜ì§ˆ (ì½”ë“œ í™•ì •íŒ)")
st.caption("CSVì—ì„œ í™•ì¸ëœ 'ì§„ì§œ ì½”ë“œ'ë¥¼ ì‚¬ìš©í•˜ê³ , ë§ˆì§€ë§‰ í˜ì´ì§€ë¡œ ì í”„í•˜ì—¬ 2026ë…„ ë°ì´í„°ë¥¼ ì¡ìŠµë‹ˆë‹¤.")

# ì‚¬ìš©ì í‚¤
USER_KEY = "5e7413b16c759d963b94776062c5a130c3446edf4d5f7f77a679b91bfd437912"
ENCODED_KEY = urllib.parse.quote(USER_KEY)
BASE_URL = "https://apis.data.go.kr/1480523/WaterQualityService/getRealTimeWaterQualityList"

# ---------------------------------------------------------
# [í™•ì¸ë¨] ê¸ˆê°• ìˆ˜ê³„ ì§„ì§œ ì½”ë“œ ë§¤í•‘ (CSV ë¶„ì„ ê²°ê³¼)
# ---------------------------------------------------------
CONFIRMED_STATIONS = [
    {"code": "S03008", "name": "ìš©ë‹´í˜¸"}, # â˜…í™•ì¸ë¨
    {"code": "S03012", "name": "ë´‰í™©ì²œ"},
    {"code": "S03011", "name": "ì´ì›"},   # â˜…í™•ì¸ë¨
    {"code": "S03007", "name": "ì¥ê³„"},
    {"code": "S03010", "name": "ì˜¥ì²œì²œ"},
    {"code": "S03003", "name": "ëŒ€ì²­í˜¸"},
    {"code": "S03009", "name": "í˜„ë„"},
    {"code": "S03002", "name": "ê°‘ì²œ"},
    {"code": "S03006", "name": "ë¯¸í˜¸ì²œ"}, # ë¯¸í˜¸ê°• êµ¬ ëª…ì¹­
    {"code": "S03013", "name": "ë‚¨ë©´"},
    {"code": "S03004", "name": "ê³µì£¼"},
    {"code": "S03014", "name": "ìœ êµ¬ì²œ"},
    {"code": "S03005", "name": "ë¶€ì—¬"},
]

# ---------------------------------------------------------
# [í•µì‹¬] ë§ˆì§€ë§‰ í˜ì´ì§€ ì í”„ ë¡œì§ (2007ë…„ íƒˆì¶œ)
# ---------------------------------------------------------
def fetch_last_page_data(station_code):
    # 1. ì¼ë‹¨ 1ê°œë§Œ ìš”ì²­í•´ì„œ 'ì „ì²´ ê°œìˆ˜(totalCount)'ë¥¼ ì•Œì•„ëƒ…ë‹ˆë‹¤.
    init_url = f"{BASE_URL}?serviceKey={ENCODED_KEY}&numOfRows=1&pageNo=1&siteId={station_code}"
    
    try:
        r1 = requests.get(init_url, verify=False, timeout=5)
        if r1.status_code != 200: return None, f"í†µì‹ ì‹¤íŒ¨({r1.status_code})"
        
        root = ET.fromstring(r1.content)
        total_str = root.findtext('.//totalCount')
        
        if not total_str or int(total_str) == 0:
            return None, "ë°ì´í„° ì—†ìŒ"
            
        total_count = int(total_str)
        
        # 2. ë§ˆì§€ë§‰ í˜ì´ì§€ ê³„ì‚° (10ê°œì”© ë³¼ ë•Œ)
        # ì˜ˆ: 500,000ê°œ -> 50,000í˜ì´ì§€
        page_size = 10
        last_page = math.ceil(total_count / page_size)
        
        # 3. ë§ˆì§€ë§‰ í˜ì´ì§€ í˜¸ì¶œ (ì—¬ê¸°ì— 2026ë…„ ë°ì´í„°ê°€ ìˆìŠµë‹ˆë‹¤!)
        final_url = f"{BASE_URL}?serviceKey={ENCODED_KEY}&numOfRows={page_size}&pageNo={last_page}&siteId={station_code}"
        
        r2 = requests.get(final_url, verify=False, timeout=10)
        if r2.status_code == 200:
            root2 = ET.fromstring(r2.content)
            items = root2.findall('.//item')
            
            if items:
                # ê²°ê³¼ íŒŒì‹±
                parsed_list = []
                for item in items:
                    parsed_list.append({child.tag: child.text for child in item})
                
                # ë‚ ì§œ(msrDate) + ì‹œê°„(msrTime) ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ -> ê°€ì¥ ìµœì‹ ì´ 0ë²ˆ
                parsed_list.sort(key=lambda x: (x.get('msrDate', ''), x.get('msrTime', '')), reverse=True)
                
                return parsed_list[0], "ì„±ê³µ"
        
        return None, "ë§ˆì§€ë§‰ í˜ì´ì§€ ë¡œë“œ ì‹¤íŒ¨"

    except Exception as e:
        return None, f"ì—ëŸ¬: {e}"

# ---------------------------------------------------------
# ë©”ì¸ UI
# ---------------------------------------------------------
if st.button("ğŸš€ 2026ë…„ ì‹¤ì‹œê°„ ë°ì´í„° ì¡°íšŒ", type="primary"):
    
    results = []
    bar = st.progress(0)
    
    # ì„±ê³µ ì¹´ìš´íŠ¸
    success_cnt = 0
    
    for i, station in enumerate(CONFIRMED_STATIONS):
        time.sleep(0.1)
        
        item, msg = fetch_last_page_data(station['code'])
        
        if item:
            success_cnt += 1
            res = {
                "ì§€ì ëª…": station['name'], # ìš°ë¦¬ê°€ í™•ì¸í•œ ì •í™•í•œ ì´ë¦„
                "ì½”ë“œ": station['code'],
                "ì‹œê°„": f"{item.get('msrDate', '')} {item.get('msrTime', '')}",
                "pH": item.get('m70', '-'),
                "DO(mg/L)": item.get('m69', '-'),
                "TOC(mg/L)": item.get('m27', '-'),
                "íƒë„(NTU)": item.get('m29', '-'),
                "ì „ê¸°ì „ë„ë„": item.get('m71', '-'),
                "ìˆ˜ì˜¨(â„ƒ)": item.get('m72', '-'),
                "ì´ì¸(T-P)": item.get('m37', '-'),
            }
            results.append(res)
        else:
            results.append({
                "ì§€ì ëª…": station['name'],
                "ì½”ë“œ": station['code'],
                "ì‹œê°„": "ì¡°íšŒì‹¤íŒ¨",
                "pH": msg
            })
            
        bar.progress((i+1)/len(CONFIRMED_STATIONS))

    # ê²°ê³¼ ì¶œë ¥
    if results:
        df = pd.DataFrame(results)
        
        # ìµœì‹  ë‚ ì§œ í™•ì¸
        valid_dates = df[df['ì‹œê°„'].str.contains('202')]['ì‹œê°„'].sort_values(ascending=False)
        latest = valid_dates.iloc[0] if not valid_dates.empty else "í™•ì¸ë¶ˆê°€"
        
        st.subheader(f"ğŸ“Š ì¡°íšŒ ê²°ê³¼ (ê¸°ì¤€: {latest})")
        
        if "2026" in str(latest) or "2025" in str(latest):
             st.success("âœ… ì„±ê³µ! ìµœì‹  ë°ì´í„°ë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
        else:
             st.warning(f"âš ï¸ ì—¬ì „íˆ ê³¼ê±° ë°ì´í„°({latest})ë¼ë©´, API ì„œë²„ ì—…ë°ì´íŠ¸ê°€ ì§€ì—°ë˜ê³  ìˆëŠ” ê²ƒì…ë‹ˆë‹¤.")
             
        st.dataframe(df, use_container_width=True)
        
        csv = df.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ğŸ“¥ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", csv, "ìˆ˜ì§ˆ_ìµœì‹ _í™•ì •.csv")
